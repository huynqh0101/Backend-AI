import os
import asyncio
import pandas as pd
import logging
import traceback
import xml.etree.ElementTree as ET
from lightrag import LightRAG, QueryParam
from lightrag.utils import EmbeddingFunc
from lightrag.kg.shared_storage import initialize_pipeline_status
from sentence_transformers import SentenceTransformer
from py2neo import Graph, Node, Relationship
import numpy as np
import nest_asyncio
import googletrans
from googletrans import Translator

# Apply nest_asyncio to solve event loop issues
nest_asyncio.apply()

logging.basicConfig(format="%(levelname)s:%(message)s", level=logging.INFO)

# ============= C·∫§U H√åNH =============
NEO4J_URI = "neo4j://localhost:7687"
NEO4J_USERNAME = "neo4j"
NEO4J_PASSWORD = "huy1552004"
NEO4J_DATABASE = "lightrag"

WORKING_DIR = "./lightrag_dongyi_neo4j"
CSV_FILE = "./data/data_translated.csv"
OLLAMA_BASE_URL = "http://localhost:11434"


# ============= OLLAMA LLM & EMBEDDING WRAPPER =============
async def ollama_model_complete(
    prompt, system_prompt=None, history_messages=[], **kwargs
) -> str:
    """Wrapper ƒë·ªÉ g·ªçi Ollama API - T∆∞∆°ng th√≠ch v·ªõi LightRAG"""
    import httpx
    
    model = kwargs.get("model", "llama3.2:latest")
    
    # ‚úÖ TH√äM SYSTEM PROMPT ƒê·ªÇ ENFORCE FORMAT
    if not system_prompt:
        system_prompt = """B·∫°n l√† tr·ª£ l√Ω AI chuy√™n tr√≠ch xu·∫•t tri th·ª©c y h·ªçc c·ªï truy·ªÅn Vi·ªát Nam.
QUY T·∫ÆC QUAN TR·ªåNG:
1. T·∫•t c·∫£ ƒë·∫ßu ra PH·∫¢I b·∫±ng ti·∫øng Vi·ªát, tuy·ªát ƒë·ªëi kh√¥ng d√πng ti·∫øng Anh.
2. M√¥ t·∫£, nh√£n, thu·ªôc t√≠nh, keywords... ƒë·ªÅu ph·∫£i l√† ti·∫øng Vi·ªát.
3. N·∫øu kh√¥ng ch·∫Øc, h√£y tr·∫£ v·ªÅ ti·∫øng Vi·ªát ƒë∆°n gi·∫£n nh·∫•t.
4. Kh√¥ng th√™m b√¨nh lu·∫≠n, gi·∫£i th√≠ch ho·∫∑c d·ªãch sang ti·∫øng Anh.
5. Gi·ªØ nguy√™n thu·∫≠t ng·ªØ y h·ªçc ti·∫øng Vi·ªát."""
    
    # T·∫°o messages
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    
    messages.extend(history_messages)
    messages.append({"role": "user", "content": prompt})
    
    try:
        async with httpx.AsyncClient(timeout=600) as client:
            response = await client.post(
                f"{OLLAMA_BASE_URL}/api/chat",
                json={
                    "model": model,
                    "messages": messages,
                    "stream": False,
                    "options": {
                        "temperature": kwargs.get("temperature", 0.0),
                        "num_ctx": kwargs.get("num_ctx", 8192),
                        "num_predict": 3072,  # ‚úÖ TƒÇNG T·ª™ 2048 L√äN 3072
                        "top_k": 1,  # ‚úÖ TH√äM: Ch·ªâ ch·ªçn token c√≥ x√°c su·∫•t cao nh·∫•t
                        "top_p": 0.1,  # ‚úÖ TH√äM: Nucleus sampling r·∫•t h·∫πp
                        "repeat_penalty": 1.1,  # ‚úÖ TH√äM: Tr√°nh l·∫∑p l·∫°i
                    }
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["message"]["content"]
            else:
                error_msg = f"Ollama API error: {response.status_code}"
                if response.status_code == 500:
                    error_msg += f"\nResponse: {response.text[:500]}"
                print(f"‚ö†Ô∏è  {error_msg}")
                raise Exception(error_msg)
    except httpx.TimeoutException:
        print("‚ö†Ô∏è  Ollama timeout - prompt qu√° d√†i ho·∫∑c model ch·∫≠m")
        raise Exception("Ollama timeout")
    except Exception as e:
        print(f"‚ö†Ô∏è  Ollama error: {e}")
        raise


async def sentence_transformer_embedding(texts: list[str]) -> np.ndarray:
    """Embedding function s·ª≠ d·ª•ng SentenceTransformer"""
    try:
        model = SentenceTransformer("all-MiniLM-L6-v2")
        embeddings = model.encode(texts, convert_to_numpy=True)
        return embeddings
    except Exception as e:
        print(f"‚ùå L·ªói embedding: {e}")
        raise


# ============= NEO4J KNOWLEDGE GRAPH CLASS =============
class DongyiKnowledgeGraph:
    """Qu·∫£n l√Ω Neo4j Knowledge Graph cho ƒê√¥ng y"""
    
    def __init__(self, uri, username, password, database="lightrag"):
        self.uri = uri
        self.username = username
        self.password = password
        self.database = database
        self.graph = Graph(uri, auth=(username, password), name=database)
        print(f"‚úÖ K·∫øt n·ªëi Neo4j database: {database}")
    
    def clear_database(self):
        """X√≥a to√†n b·ªô d·ªØ li·ªáu c≈©"""
        print("üóëÔ∏è  ƒêang x√≥a d·ªØ li·ªáu c≈©...")
        self.graph.run("MATCH (n) DETACH DELETE n")
        print("‚úÖ ƒê√£ x√≥a d·ªØ li·ªáu c≈©")
    
    def import_from_graphml(self, graphml_file):
        """Import GraphML file v√†o Neo4j - MERGE ƒë·ªÉ tr√°nh tr√πng"""
        try:
            print(f"\nüì• ƒêang import GraphML: {graphml_file}")
            tree = ET.parse(graphml_file)
            root = tree.getroot()
            
            ns = {'graphml': 'http://graphml.graphdrawing.org/xmlns'}
            
            # Import nodes
            nodes = root.findall('.//graphml:node', ns)
            print(f"   T√¨m th·∫•y {len(nodes)} nodes...")
            
            node_count = 0
            for node in nodes:
                node_id = node.get('id')
                entity_type = "Unknown"
                description = ""
                for data in node.findall('graphml:data', ns):
                    key = data.get('key')
                    if key in ['d1', 'entity_type']:
                        entity_type = data.text or "Unknown"
                    elif key in ['d2', 'description']:
                        description = ensure_vietnamese(data.text or "")
                # MERGE node ƒë·ªÉ tr√°nh tr√πng
                query = """
                MERGE (e:Entity {id: $node_id})
                ON CREATE SET 
                    e.type = $entity_type,
                    e.description = $description,
                    e.displayName = $node_id,
                    e.created_at = datetime()
                ON MATCH SET
                    e.type = $entity_type,
                    e.description = $description,
                    e.updated_at = datetime()
                """
                self.graph.run(query, node_id=node_id, entity_type=entity_type, 
                             description=description)
                node_count += 1
                
                if node_count % 100 == 0:
                    print(f"      ƒê√£ import {node_count}/{len(nodes)} nodes...")
            
            print(f"   ‚úÖ ƒê√£ import {node_count} nodes")
            
            # Import edges
            edges = root.findall('.//graphml:edge', ns)
            print(f"   T√¨m th·∫•y {len(edges)} relationships...")
            
            rel_count = 0
            for edge in edges:
                source_id = edge.get('source')
                target_id = edge.get('target')
                weight = 1.0
                description = ""
                keywords = ""
                for data in edge.findall('graphml:data', ns):
                    key = data.get('key')
                    if key in ['d5', 'weight']:
                        try:
                            weight = float(data.text or 1.0)
                        except:
                            weight = 1.0
                    elif key in ['d6', 'description']:
                        description = ensure_vietnamese(data.text or "")
                    elif key in ['d7', 'keywords']:
                        keywords = data.text or ""
                
                # MERGE relationship
                query = """
                MATCH (source:Entity {id: $source_id})
                MATCH (target:Entity {id: $target_id})
                MERGE (source)-[r:RELATED]->(target)
                ON CREATE SET
                    r.weight = $weight,
                    r.description = $description,
                    r.keywords = $keywords,
                    r.created_at = datetime()
                ON MATCH SET
                    r.weight = $weight,
                    r.description = $description,
                    r.keywords = $keywords,
                    r.updated_at = datetime()
                """
                self.graph.run(query, source_id=source_id, target_id=target_id,
                             weight=weight, description=description, keywords=keywords)
                rel_count += 1
                
                if rel_count % 100 == 0:
                    print(f"      ƒê√£ import {rel_count}/{len(edges)} relationships...")
            
            print(f"   ‚úÖ ƒê√£ import {rel_count} relationships")
            
        except Exception as e:
            print(f"‚ùå L·ªói import GraphML: {e}")
            traceback.print_exc()
    
    def get_stats(self):
        """Th·ªëng k√™ database"""
        entity_count = self.graph.run("MATCH (e:Entity) RETURN count(e) as count").evaluate()
        rel_count = self.graph.run("MATCH ()-[r:RELATED]->() RETURN count(r) as count").evaluate()
        
        print(f"\nüìä Th·ªëng k√™ Neo4j ({self.database}):")
        print(f"   - Entities: {entity_count}")
        print(f"   - Relationships: {rel_count}")
        return {"entities": entity_count, "relationships": rel_count}
    
    
def csv_to_documents(csv_path: str) -> str:
    """Chuy·ªÉn CSV th√†nh text documents"""
    print(f"\nüìñ ƒê·ªçc file CSV: {csv_path}")
    df = pd.read_csv(csv_path, encoding="utf-8", on_bad_lines='skip', engine='python')
    
    print(f"‚úÖ ƒê√£ ƒë·ªçc {len(df)} d√≤ng d·ªØ li·ªáu")
    
    documents = []
    
    for idx, row in df.iterrows():
        chuong_so = row.get('chuong_so', '')
        tieu_de_chuong = row.get('tieu_de_chuong', '')
        ten_bai_thuoc = row.get('ten_bai_thuoc', '')
        chua_tri = row.get('chua_tri', '')
        lieu_luong_cach_dung = row.get('lieu_luong_cach_dung', '')
        cong_hieu = row.get('cong_hieu', '')
        chu_y = row.get('chu_y', '')
        doi_tuong_phu_hop = row.get('doi_tuong_phu_hop', '')
        
        if pd.isna(ten_bai_thuoc) or not ten_bai_thuoc:
            continue
        
        doc = f"""B√ÄI THU·ªêC: {ten_bai_thuoc}
Ch·ªØa tr·ªã: {chua_tri if pd.notna(chua_tri) else 'N/A'}
Li·ªÅu l∆∞·ª£ng: {lieu_luong_cach_dung if pd.notna(lieu_luong_cach_dung) else 'N/A'}
C√¥ng hi·ªáu: {cong_hieu if pd.notna(cong_hieu) else 'N/A'}
---
"""
        documents.append(doc)
        
        if idx < 3:
            print(f"\nüìÑ Document {idx + 1}:")
            print(doc[:150] + "...")
    
    print(f"\n‚úÖ ƒê√£ t·∫°o {len(documents)} documents")
    return "\n\n".join(documents)

async def initialize_lightrag():
    """Kh·ªüi t·∫°o LightRAG v·ªõi Ollama"""
    print("\nüöÄ Kh·ªüi t·∫°o LightRAG...")
    
    os.makedirs(WORKING_DIR, exist_ok=True)
    
    try:
        rag = LightRAG(
            working_dir=WORKING_DIR,
            
            # LLM config - Ollama
            llm_model_func=ollama_model_complete,
            llm_model_name="llama3.2:latest",
            llm_model_max_async=1,
            llm_model_kwargs={
                "model": "llama3.2:latest",
                "temperature": 0.0,
                "num_ctx": 8192
            },
            
            # Embedding config - SentenceTransformer
            embedding_func=EmbeddingFunc(
                embedding_dim=384,
                max_token_size=512,
                func=sentence_transformer_embedding,
            ),
            
            # Graph config
            chunk_token_size=600,  # ‚úÖ GI·∫¢M T·ª™ 800 XU·ªêNG 600 (chunks nh·ªè h∆°n = √≠t l·ªói h∆°n)
            chunk_overlap_token_size=50,
        )
        
        print("   ƒêang kh·ªüi t·∫°o storages...")
        await rag.initialize_storages()
        
        print("   ƒêang kh·ªüi t·∫°o pipeline status...")
        await initialize_pipeline_status()
        
        print("‚úÖ LightRAG ƒë√£ s·∫µn s√†ng")
        return rag
        
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o LightRAG: {e}")
        traceback.print_exc()
        return None


# ============= B∆Ø·ªöC 3: INSERT D·ªÆ LI·ªÜU =============
async def build_knowledge_graph(rag: LightRAG, documents: str):
    """Insert documents v√†o LightRAG"""
    print("\nüì• B·∫Øt ƒë·∫ßu insert d·ªØ li·ªáu v√†o LightRAG...")
    print(f"   T·ªïng ƒë·ªô d√†i: {len(documents)} k√Ω t·ª±")
    
    # ‚úÖ GI·∫¢M CHUNK SIZE ƒê·ªÇ TR√ÅNH QU√Å T·∫¢I
    max_chunk_size = 20000  # Gi·∫£m t·ª´ 50000 xu·ªëng 20000
    chunks = []
    current_chunk = ""
    
    for doc in documents.split("\n\n"):
        if len(current_chunk) + len(doc) > max_chunk_size:
            chunks.append(current_chunk)
            current_chunk = doc
        else:
            current_chunk += "\n\n" + doc
    
    if current_chunk:
        chunks.append(current_chunk)
    
    print(f"   Chia th√†nh {len(chunks)} chunks")
    
    # Insert t·ª´ng chunk
    for i, chunk in enumerate(chunks, 1):
        print(f"   üì• ƒêang insert chunk {i}/{len(chunks)}...")
        try:
            await rag.ainsert(chunk)
            print(f"   ‚úÖ Chunk {i} ho√†n t·∫•t")
            await asyncio.sleep(3)  # ‚úÖ TƒÇNG DELAY
        except Exception as e:
            print(f"   ‚ö†Ô∏è  L·ªói chunk {i}: {str(e)[:200]}")
            continue
    
    print("‚úÖ ƒê√£ insert xong v√†o LightRAG!")


# ============= B∆Ø·ªöC 4: TEST QUERY =============
async def test_query(rag: LightRAG):
    """Test query"""
    print("\nüîç Test query...")
    
    test_queries = [
        "B√†i thu·ªëc n√†o ch·ªØa s·ªët cao?",
    ]
    
    for query in test_queries:
        print(f"\n‚ùì Query: {query}")
        try:
            result = await rag.aquery(
                query,
                param=QueryParam(mode="naive", only_need_context=False, top_k=3)  # ‚úÖ D√ôNG "naive" MODE
            )
            print(f"üìù K·∫øt qu·∫£:\n{result[:500]}...")
        except Exception as e:
            print(f"‚ùå L·ªói: {e}")
            traceback.print_exc()


# ============= MAIN =============
async def main():
    print("="*70)
    print("üè• LIGHTRAG + OLLAMA + NEO4J - ƒê√îNG Y KNOWLEDGE GRAPH")
    print("="*70)
    
    dongyi_kg = None
    rag = None
    
    try:
        # B∆∞·ªõc 1: ƒê·ªçc CSV
        documents = csv_to_documents(CSV_FILE)
        
        # B∆∞·ªõc 2: Kh·ªüi t·∫°o LightRAG
        rag = await initialize_lightrag()
        if not rag:
            return
        
        # B∆∞·ªõc 3: Build Knowledge Graph
        await build_knowledge_graph(rag, documents)
        
        # B∆∞·ªõc 4: Test query
        await test_query(rag)
        
        # B∆∞·ªõc 5: Import v√†o Neo4j
        print("\n" + "="*70)
        print("üì§ IMPORT V√ÄO NEO4J")
        print("="*70)
        
        graphml_file = os.path.join(WORKING_DIR, "graph_chunk_entity_relation.graphml")
        
        if os.path.exists(graphml_file):
            dongyi_kg = DongyiKnowledgeGraph(NEO4J_URI, NEO4J_USERNAME, 
                                            NEO4J_PASSWORD, NEO4J_DATABASE)
            
            # H·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën x√≥a d·ªØ li·ªáu c≈© kh√¥ng
            choice = input("\n‚ö†Ô∏è  X√≥a d·ªØ li·ªáu c≈© trong Neo4j? (y/n): ").strip().lower()
            if choice == 'y':
                dongyi_kg.clear_database()
            
            # Import GraphML
            dongyi_kg.import_from_graphml(graphml_file)
            
            # Hi·ªÉn th·ªã stats
            dongyi_kg.get_stats()
            
            print(f"\nüìä Xem trong Neo4j Browser: http://localhost:7474")
            print(f"   :use {NEO4J_DATABASE}")
            print(f"   MATCH (n)-[r]->(m) RETURN n,r,m LIMIT 25")
            
        else:
            print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y GraphML: {graphml_file}")
        
    except Exception as e:
        print(f"\n‚ùå L·ªñI: {e}")
        traceback.print_exc()
    
    finally:
        if rag:
            try:
                await rag.close_storages()
                print("\n‚úì ƒê√£ ƒë√≥ng LightRAG")
            except:
                pass
    
    print("\n" + "="*70)
    print("‚úÖ HO√ÄN T·∫§T!")
    print("="*70)


if __name__ == "__main__":
    # Ki·ªÉm tra dependencies
    print("üì¶ Ki·ªÉm tra dependencies...")
    try:
        import httpx
        import sentence_transformers
        from py2neo import Graph
    except ImportError as e:
        print(f"‚ö†Ô∏è  Thi·∫øu package: {e}")
        print("Ch·∫°y: pip install httpx sentence-transformers py2neo")
        print(f"‚ö†Ô∏è  Thi·∫øu package: {e}")
        print("Ch·∫°y: pip install httpx sentence-transformers py2neo")
        exit(1)
    asyncio.run(main())