import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.utils import EmbeddingFunc
from sentence_transformers import SentenceTransformer
from py2neo import Graph
import re
from unidecode import unidecode

WORKING_DIR = "./lightrag_dongyi_neo4j"
NEO4J_URI = "neo4j://localhost:7687"
NEO4J_USERNAME = "neo4j"
NEO4J_PASSWORD = "huy1552004"
NEO4J_DATABASE = "lightrag"

async def sentence_transformer_embedding(texts: list[str]):
    model = SentenceTransformer("all-MiniLM-L6-v2")
    return model.encode(texts, convert_to_numpy=True)

async def ollama_model_complete(
    prompt, system_prompt=None, history_messages=[], **kwargs
) -> str:
    import httpx
    model = kwargs.get("model", "llama3.2:latest")
    if not system_prompt:
        system_prompt = "B·∫°n l√† tr·ª£ l√Ω AI ƒê√¥ng y, tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.extend(history_messages)
    messages.append({"role": "user", "content": prompt})
    async with httpx.AsyncClient(timeout=600) as client:
        response = await client.post(
            "http://localhost:11434/api/chat",
            json={
                "model": model,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": kwargs.get("temperature", 0.0),
                    "num_ctx": kwargs.get("num_ctx", 8192),
                    "num_predict": 3072,
                    "top_k": 1,
                    "top_p": 0.1,
                    "repeat_penalty": 1.1,
                }
            }
        )
        result = response.json()
        return result["message"]["content"]

def normalize_text(text: str) -> str:
    """Chu·∫©n h√≥a text: b·ªè d·∫•u, chuy·ªÉn th∆∞·ªùng"""
    text = unidecode(text.lower())
    text = re.sub(r'[^\w\s]', ' ', text)
    return ' '.join(text.split())

def query_neo4j(graph: Graph, user_query: str, top_k: int = 5):
    """Truy v·∫•n Neo4j ƒë·ªÉ l·∫•y entities v√† relations"""
    normalized_query = normalize_text(user_query)
    keywords = normalized_query.split()
    
    entity_query = """
    MATCH (e:Entity)
    WHERE ANY(keyword IN $keywords WHERE 
        toLower(e.description) CONTAINS keyword OR 
        toLower(e.displayName) CONTAINS keyword
    )
    OR toLower(e.description) CONTAINS toLower($original_query)
    OR toLower(e.displayName) CONTAINS toLower($original_query)
    RETURN e.displayName as name, e.description as description, e.type as type
    LIMIT $limit
    """
    entities = graph.run(entity_query, 
                        keywords=keywords, 
                        original_query=user_query,
                        limit=top_k).data()
    
    rel_query = """
    MATCH (e1:Entity)-[r:RELATED]->(e2:Entity)
    WHERE ANY(keyword IN $keywords WHERE 
        toLower(e1.description) CONTAINS keyword OR
        toLower(e2.description) CONTAINS keyword OR
        toLower(r.description) CONTAINS keyword OR
        toLower(e1.displayName) CONTAINS keyword OR
        toLower(e2.displayName) CONTAINS keyword
    )
    OR toLower(e1.description) CONTAINS toLower($original_query)
    OR toLower(e2.description) CONTAINS toLower($original_query)
    OR toLower(r.description) CONTAINS toLower($original_query)
    RETURN e1.displayName as source, 
           r.description as relation, 
           e2.displayName as target,
           r.weight as weight
    ORDER BY r.weight DESC
    LIMIT $limit
    """
    relations = graph.run(rel_query, 
                         keywords=keywords,
                         original_query=user_query,
                         limit=top_k).data()
    
    return entities, relations

def build_neo4j_context(entities, relations):
    """X√¢y d·ª±ng context t·ª´ Neo4j"""
    context = "## Th√¥ng tin t·ª´ Knowledge Graph (Neo4j):\n\n"
    
    if entities:
        context += "### C√°c kh√°i ni·ªám li√™n quan:\n"
        for e in entities:
            # R√∫t g·ªçn description ƒë·ªÉ tr√°nh qu√° d√†i
            desc = e['description'][:300] + "..." if len(e['description']) > 300 else e['description']
            context += f"- **{e['name']}** ({e['type']}): {desc}\n"
        context += "\n"
    
    if relations:
        context += "### C√°c m·ªëi quan h·ªá:\n"
        for r in relations:
            rel_desc = r['relation'][:200] + "..." if len(r['relation']) > 200 else r['relation']
            context += f"- {r['source']} ‚Üí {r['target']}: {rel_desc}\n"
        context += "\n"
    
    return context

async def main():
    print("üîç Truy v·∫•n Hybrid: LightRAG Vector + Neo4j Graph")
    
    # Kh·ªüi t·∫°o LightRAG
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=ollama_model_complete,
        llm_model_name="llama3.2:latest",
        llm_model_kwargs={
            "model": "llama3.2:latest",
            "temperature": 0.0,
            "num_ctx": 8192
        },
        embedding_func=EmbeddingFunc(
            embedding_dim=384,
            max_token_size=512,
            func=sentence_transformer_embedding,
        ),
        chunk_token_size=600,
        chunk_overlap_token_size=50,
    )
    await rag.initialize_storages()
    
    # K·∫øt n·ªëi Neo4j
    graph = Graph(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD), name=NEO4J_DATABASE)
    
    while True:
        user_query = input("\nNh·∫≠p c√¢u h·ªèi ƒê√¥ng y (ho·∫∑c 'exit' ƒë·ªÉ tho√°t): ").strip()
        if user_query.lower() == "exit":
            break
        
        try:
            print("\nüìä ƒêang t√¨m ki·∫øm...")
            
            # 1. LightRAG vector search ƒë·ªÉ l·∫•y context t·ª´ chunks
            lightrag_context = await rag.aquery(
                user_query,
                param=QueryParam(
                    mode="naive",
                    only_need_context=True,
                    top_k=3
                )
            )
            
            # 2. Neo4j graph query ƒë·ªÉ l·∫•y entities v√† relations
            entities, relations = query_neo4j(graph, user_query, top_k=5)
            neo4j_context = build_neo4j_context(entities, relations) if (entities or relations) else ""
            
            # 3. K·∫øt h·ª£p c·∫£ 2 ngu·ªìn context
            combined_context = f"""## Context t·ª´ Vector Search (LightRAG):
{lightrag_context}

{neo4j_context}
"""
            
            print(f"\nüìö T√¨m th·∫•y: {len(entities)} entities, {len(relations)} relations")
            
            # 4. Prompt t·ªëi ∆∞u cho LLM
            prompt = f"""B·∫°n l√† chuy√™n gia Y h·ªçc c·ªï truy·ªÅn Vi·ªát Nam. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p.

## H∆Ø·ªöNG D·∫™N:
1. ƒê·ªçc k·ªπ to√†n b·ªô th√¥ng tin t·ª´ c∆° s·ªü tri th·ª©c b√™n d∆∞·ªõi
2. T·ªïng h·ª£p v√† ph√¢n t√≠ch th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi
3. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, r√µ r√†ng, ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c
4. N·∫øu c√≥ nhi·ªÅu b√†i thu·ªëc/ph∆∞∆°ng ph√°p, h√£y li·ªát k√™ t·ª´ng m·ª•c v·ªõi c·∫•u tr√∫c:
   - T√™n b√†i thu·ªëc/ph∆∞∆°ng ph√°p
   - C√¥ng d·ª•ng/ch·ªØa b·ªánh g√¨
   - Th√†nh ph·∫ßn (n·∫øu c√≥)
   - C√°ch d√πng/li·ªÅu l∆∞·ª£ng (n·∫øu c√≥)
5. Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin c√≥ trong context, KH√îNG b·ªãa ƒë·∫∑t
6. N·∫øu kh√¥ng ƒë·ªß th√¥ng tin, h√£y n√≥i r√µ ph·∫ßn n√†o thi·∫øu

## TH√îNG TIN T·ª™ C∆† S·ªû TRI TH·ª®C:
{combined_context}

## C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG:
{user_query}

## C√ÇU TR·∫¢ L·ªúI C·ª¶A B·∫†N (ch·ªâ b·∫±ng ti·∫øng Vi·ªát):"""
            
            print("\nü§ñ ƒêang sinh c√¢u tr·∫£ l·ªùi...")
            answer = await ollama_model_complete(prompt, model="llama3.2:latest", temperature=0.0)
            
            print("\n‚úÖ C√¢u tr·∫£ l·ªùi:")
            print(answer)
            
        except Exception as e:
            print(f"L·ªói truy v·∫•n: {e}")
            import traceback
            traceback.print_exc()
    
    await rag.close_storages()

if __name__ == "__main__":
    asyncio.run(main())