# H·ªá th·ªëng RAG ƒê√¥ng y - Neo4j + Ollama (C·∫¨P NH·∫¨T CHO KG M·ªöI)
# ------------------------------------------------
import os
import asyncio
import logging
import traceback
from neo4j import GraphDatabase
from typing import List, Dict
import json
import re
import unicodedata
import requests

# --- C·∫•u h√¨nh ---
print("--- H·ªá th·ªëng RAG ƒê√¥ng y (Neo4j + Ollama) - KG V2 ---")

# Neo4j Configuration
NEO4J_URI = "neo4j://localhost:7687"
NEO4J_USERNAME = "neo4j"
NEO4J_PASSWORD = "huy1552004"
NEO4J_DATABASE = "dongyi"

# Ollama Configuration
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_MODEL = "llama3.2:latest"

print(f"‚úì Neo4j Database: {NEO4J_DATABASE}")
print(f"‚úì Ollama URL: {OLLAMA_BASE_URL}")
print(f"‚úì Ollama Model: {OLLAMA_MODEL}")

# --- Text Normalizer ---
class TextNormalizer:
    """Chu·∫©n h√≥a text ƒë·ªÉ t√¨m ki·∫øm t·ªët h∆°n"""
    
    @staticmethod
    def remove_accents(text: str) -> str:
        """B·ªè d·∫•u ti·∫øng Vi·ªát"""
        if not isinstance(text, str):
            return ""
        
        # Normalize Unicode (NFD = t√°ch k√Ω t·ª± v√† d·∫•u)
        nfd = unicodedata.normalize('NFD', text)
        
        # Lo·∫°i b·ªè c√°c d·∫•u (Mn = Mark, Nonspacing)
        without_accents = ''.join(
            char for char in nfd 
            if unicodedata.category(char) != 'Mn'
        )
        
        # X·ª≠ l√Ω ƒê/ƒë ƒë·∫∑c bi·ªát
        without_accents = without_accents.replace('ƒê', 'D').replace('ƒë', 'd')
        
        return without_accents
    
    @staticmethod
    def normalize(text: str, keep_case: bool = False) -> str:
        """Chu·∫©n h√≥a text to√†n di·ªán"""
        if not isinstance(text, str):
            return ""
        
        # 1. Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát (gi·ªØ ch·ªØ, s·ªë, kho·∫£ng tr·∫Øng)
        text = re.sub(r'[^\w\s]', ' ', text)
        
        # 2. Chu·∫©n h√≥a kho·∫£ng tr·∫Øng (nhi·ªÅu space ‚Üí 1 space)
        text = re.sub(r'\s+', ' ', text).strip()
        
        # 3. Lowercase (tr·ª´ khi keep_case=True)
        if not keep_case:
            text = text.lower()
        
        return text
    
    @staticmethod
    def normalize_for_search(text: str) -> str:
        """Chu·∫©n h√≥a cho t√¨m ki·∫øm: b·ªè d·∫•u + lowercase + trim"""
        text = TextNormalizer.remove_accents(text)
        text = TextNormalizer.normalize(text, keep_case=False)
        return text
    
    @staticmethod
    def create_search_variants(text: str) -> list:
        """T·∫°o c√°c bi·∫øn th·ªÉ ƒë·ªÉ t√¨m ki·∫øm"""
        variants = set()
        
        # Variant 1: G·ªëc
        variants.add(text.strip())
        
        # Variant 2: Lowercase
        variants.add(text.lower().strip())
        
        # Variant 3: B·ªè d·∫•u
        variants.add(TextNormalizer.remove_accents(text).lower().strip())
        
        # Variant 4: Normalize ho√†n to√†n
        variants.add(TextNormalizer.normalize_for_search(text))
        
        # Variant 5: B·ªè "c√¢y" ·ªü ƒë·∫ßu
        if text.lower().startswith('c√¢y '):
            variants.add(text[4:].strip())
            variants.add(TextNormalizer.normalize_for_search(text[4:]))
        
        return list(variants)


# --- Query Preprocessor (S·ª¨A ƒê·ªîI) ---
class QueryPreprocessor:
    """X·ª≠ l√Ω c√¢u h·ªèi ƒë·ªÉ tr√≠ch xu·∫•t t·ª´ kh√≥a"""
    
    STOP_WORDS = {
        'b√†i', 'thu·ªëc', 'n√†o', 'tr·ªã', 'ch·ªØa', 'ƒëi·ªÅu', 'c√≥', 'ƒë·ªÉ',
        'l√†', 'g√¨', 'th·∫ø', 'nh∆∞', 'th√¨', 'ƒë∆∞·ª£c', 'c·ªßa', 'cho', 'v√†',
        'm·ªôt', 'c√°c', 'n√†y', 'kia', 'ƒë√≥', '·∫•y', 'm√†', 'v·ªõi', 'hay',
        'ho·∫∑c', 'nh∆∞ng', 't√¥i', 'mu·ªën', 'c·∫ßn', 't√¨m', 'ki·∫øm', 'xem',
        'bi·∫øt', 'h·ªèi', 'gi√∫p', 'em', 'anh', 'ch·ªã'
    }
    
    DISEASE_KEYWORDS = {
        's·ªët', 'ho', 'vi√™m', 'ƒëau', 'c·∫£m', 'nhi·ªÖm', 'l·∫°nh', 'n√≥ng',
        'kh√≥', 'ti√™u', 't√°o', 'b√≥n', 'ch·∫£y', 'ki·∫øt', 'l·ªµ',
        'm·ªát', 'nh·ª©c', 'ƒë·∫ßu', 'h·ªçng', 'ph·ªïi', 'gan', 'th·∫≠n', 'tim',
        'kh√°t', 'phi·ªÅn', 'bu·ªìn'
    }
    
    HERB_KEYWORDS = {
        'c√¢y', 'th·∫£o', 'd∆∞·ª£c', 'li·ªáu', 'h·ªç', 'th·ª±c', 'v·∫≠t', 'l√°', 'r·ªÖ', 
        'th√¢n', 'hoa', 'qu·∫£', 'c·ªß', 'v·ªè'
    }
    
    @staticmethod
    def detect_query_type(query: str) -> str:
        """Ph√°t hi·ªán lo·∫°i c√¢u h·ªèi - C·∫¢I TI·∫æN"""
        query_normalized = TextNormalizer.normalize_for_search(query)
        
        # Check herb keywords
        herb_count = sum(1 for kw in QueryPreprocessor.HERB_KEYWORDS 
                        if kw in query_normalized)
        disease_count = sum(1 for kw in QueryPreprocessor.DISEASE_KEYWORDS 
                           if kw in query_normalized)
        
        if herb_count > disease_count:
            return "herb"
        elif disease_count > 0:
            return "disease"
        else:
            return "general"
    
    @staticmethod
    def extract_keywords(query: str) -> List[str]:
        """Tr√≠ch xu·∫•t keywords - C·∫¢I TI·∫æN"""
        query_normalized = TextNormalizer.normalize_for_search(query)
        words = re.findall(r'\w+', query_normalized)
        
        # Lo·∫°i b·ªè stop words (ƒë√£ normalize)
        stop_words_normalized = {TextNormalizer.normalize_for_search(w) 
                                 for w in QueryPreprocessor.STOP_WORDS}
        keywords = [w for w in words 
                   if w not in stop_words_normalized and len(w) > 1]
        
        if not keywords:
            return [query_normalized]
        
        # ∆Øu ti√™n disease keywords
        disease_keywords_normalized = {TextNormalizer.normalize_for_search(w) 
                                       for w in QueryPreprocessor.DISEASE_KEYWORDS}
        disease_found = [k for k in keywords if k in disease_keywords_normalized]
        if disease_found:
            return disease_found
        
        return keywords
    
    @staticmethod
    def build_search_patterns(query: str) -> List[str]:
        """T·∫°o search patterns - C·∫¢I TI·∫æN"""
        patterns = set()
        
        # Pattern 1: Nguy√™n g·ªëc (trim)
        patterns.add(query.strip())
        
        # Pattern 2: Lowercase
        patterns.add(query.lower().strip())
        
        # Pattern 3: Normalize (b·ªè d·∫•u)
        patterns.add(TextNormalizer.normalize_for_search(query))
        
        # Pattern 4: T·ª´ keywords
        keywords = QueryPreprocessor.extract_keywords(query)
        if len(keywords) > 1:
            patterns.add(' '.join(keywords))
        patterns.update(keywords)
        
        # Pattern 5: Variants (b·ªè "c√¢y", "thu·ªëc"...)
        variants = TextNormalizer.create_search_variants(query)
        patterns.update(variants)
        
        # Lo·∫°i b·ªè empty v√† tr√πng l·∫∑p, gi·ªØ th·ª© t·ª±
        result = []
        for p in patterns:
            p_clean = p.strip()
            if p_clean and p_clean not in result:
                result.append(p_clean)
        
        return result


# --- Ollama Service ---
class OllamaService:
    """Service ƒë·ªÉ g·ªçi Ollama local LLM"""
    
    def __init__(self, base_url=OLLAMA_BASE_URL, model=OLLAMA_MODEL):
        self.base_url = base_url.rstrip('/')
        self.model = model
        self.api_url = f"{self.base_url}/api/generate"
        self._test_connection()
    
    def _test_connection(self):
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_names = [m['name'] for m in models]
                print(f"‚úì K·∫øt n·ªëi Ollama th√†nh c√¥ng")
                print(f"  Models c√≥ s·∫µn: {', '.join(model_names)}")
                
                if self.model not in model_names:
                    print(f"‚ö†Ô∏è  Model '{self.model}' ch∆∞a ƒë∆∞·ª£c pull")
                    if model_names:
                        self.model = model_names[0]
                        print(f"   ‚úì T·ª± ƒë·ªông chuy·ªÉn sang model: {self.model}")
                    else:
                        raise ValueError(f"Kh√¥ng c√≥ model n√†o. Ch·∫°y: ollama pull llama3.2")
            else:
                raise ConnectionError("Kh√¥ng th·ªÉ k·∫øt n·ªëi Ollama")
        except requests.exceptions.RequestException as e:
            print(f"‚úó Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Ollama t·∫°i {self.base_url}")
            print(f"  L·ªói: {e}")
            raise
    
    def generate_answer(self, question: str, context: List[Dict]) -> str:
        try:
            context_text = self._format_context(context)
            
            prompt = f"""B·∫°n l√† chuy√™n gia Y h·ªçc ƒê√¥ng y Vi·ªát Nam. D·ª±a tr√™n th√¥ng tin sau ƒë√¢y t·ª´ c∆° s·ªü tri th·ª©c, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch chi ti·∫øt, chuy√™n nghi·ªáp v√† d·ªÖ hi·ªÉu.

TH√îNG TIN T·ª™ C∆† S·ªû TRI TH·ª®C:
{context_text}

C√ÇU H·ªéI: {question}

H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, chuy√™n nghi·ªáp v√† d·ªÖ hi·ªÉu
- N√™u r√µ t√™n b√†i thu·ªëc, nguy√™n li·ªáu, li·ªÅu l∆∞·ª£ng
- Gi·∫£i th√≠ch c√¥ng hi·ªáu v√† c√°ch s·ª≠ d·ª•ng
- N·∫øu c√≥ nhi·ªÅu b√†i thu·ªëc, so s√°nh v√† ƒë∆∞a ra khuy·∫øn ngh·ªã
- Lu√¥n nh·∫Øc nh·ªü "n√™n tham kh·∫£o √Ω ki·∫øn b√°c sƒ© ƒê√¥ng y tr∆∞·ªõc khi s·ª≠ d·ª•ng"
- N·∫øu kh√¥ng c√≥ th√¥ng tin, h√£y th√†nh th·∫≠t n√≥i "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin v·ªÅ..."

TR·∫¢ L·ªúI:"""

            print("ü§ñ ƒêang g·ªçi Ollama...")
            
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 1000
                }
            }
            
            response = requests.post(self.api_url, json=payload, timeout=120)
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get('response', '').strip()
                print(f"‚úì Ollama response received ({len(answer)} chars)")
                return answer
            else:
                return self._fallback_answer(context)
                
        except Exception as e:
            print(f"‚ö†Ô∏è  L·ªói khi g·ªçi Ollama: {e}")
            return self._fallback_answer(context)
    
    def _format_context(self, context: List[Dict]) -> str:
        if not context:
            return "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan."
        
        formatted = []
        for i, item in enumerate(context, 1):
            text = f"\n--- B√ÄI THU·ªêC {i}: {item['ten_bai_thuoc']} ---\n"
            text += item['description']
            formatted.append(text)
        
        return "\n".join(formatted)
    
    def _fallback_answer(self, context: List[Dict]) -> str:
        if not context:
            return "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong c∆° s·ªü tri th·ª©c."
        
        answer = "D·ª±a tr√™n c∆° s·ªü tri th·ª©c, t√¥i t√¨m th·∫•y c√°c th√¥ng tin sau:\n\n"
        for i, item in enumerate(context, 1):
            answer += f"**{i}. {item['ten_bai_thuoc']}**\n"
            answer += f"{item['description']}\n\n"
        
        answer += "\n‚ö†Ô∏è  *L∆∞u √Ω: N√™n tham kh·∫£o √Ω ki·∫øn b√°c sƒ© ƒê√¥ng y tr∆∞·ªõc khi s·ª≠ d·ª•ng.*"
        return answer


# --- Neo4j Query Helper (S·ª¨A QUERY) ---
class DongyiQueryHelper:
    def __init__(self, uri, username, password, database="dongyi"):
        self.driver = GraphDatabase.driver(uri, auth=(username, password))
        self.database = database
        self.preprocessor = QueryPreprocessor()
        self.normalizer = TextNormalizer()  # ‚Üê TH√äM
        
    def close(self):
        self.driver.close()
    
    def _query_by_disease(self, query_text: str, limit: int):
        """Query 1: T√¨m theo B·ªÜNH - IMPROVED"""
        def execute(session):
            variants = TextNormalizer.create_search_variants(query_text)
            query = """
            MATCH (r:B√ÄI_THU·ªêC)-[:ƒêI·ªÄU_TR·ªä]->(b:B·ªÜNH)
            WHERE toLower(b.t√™n_b·ªánh) CONTAINS toLower($query_text)
               OR ANY(variant IN $variants WHERE toLower(b.t√™n_b·ªánh) CONTAINS toLower(variant))
            OPTIONAL MATCH (r)-[rel:CH·ª®A_NGUY√äN_LI·ªÜU]->(n:NGUY√äN_LI·ªÜU)
            OPTIONAL MATCH (r)-[:C√ì_C√îNG_HI·ªÜU]->(e:C√îNG_HI·ªÜU)
            OPTIONAL MATCH (r)-[:TR·ªä_TRI·ªÜU_CH·ª®NG]->(s:TRI·ªÜU_CH·ª®NG)
            RETURN DISTINCT
                r.t√™n_b√†i_thu·ªëc AS ten_bai_thuoc,
                b.t√™n_b·ªánh AS ten_benh,
                r.li·ªÅu_l∆∞·ª£ng_c√°ch_d√πng AS lieu_luong,
                r.ch√∫_√Ω AS chu_y,
                r.ƒë·ªëi_t∆∞·ª£ng_ph√π_h·ª£p AS doi_tuong,
                collect(DISTINCT n.t√™n_nguy√™n_li·ªáu) AS nguyen_lieu,
                collect(DISTINCT e.t√™n_c√¥ng_hi·ªáu) AS cong_hieu,
                collect(DISTINCT s.m√¥_t·∫£) AS trieu_chung
            LIMIT $limit
            """
            results = session.run(query, query_text=query_text, variants=variants, limit=limit)
            return self._format_results(results, "b·ªánh")
        return execute
    
    def _query_by_symptom(self, query_text: str, limit: int):
        """Query 2: T√¨m theo TRI·ªÜU_CH·ª®NG"""
        def execute(session):
            query = """
            MATCH (r:B√ÄI_THU·ªêC)-[:TR·ªä_TRI·ªÜU_CH·ª®NG]->(s:TRI·ªÜU_CH·ª®NG)
            WHERE toLower(s.m√¥_t·∫£) CONTAINS toLower($query_text)
            OPTIONAL MATCH (r)-[:ƒêI·ªÄU_TR·ªä]->(b:B·ªÜNH)
            OPTIONAL MATCH (r)-[rel:CH·ª®A_NGUY√äN_LI·ªÜU]->(n:NGUY√äN_LI·ªÜU)
            OPTIONAL MATCH (r)-[:C√ì_C√îNG_HI·ªÜU]->(e:C√îNG_HI·ªÜU)
            RETURN DISTINCT
                r.t√™n_b√†i_thu·ªëc AS ten_bai_thuoc,
                s.m√¥_t·∫£ AS trieu_chung_chinh,
                r.li·ªÅu_l∆∞·ª£ng_c√°ch_d√πng AS lieu_luong,
                collect(DISTINCT b.t√™n_b·ªánh) AS benh,
                collect(DISTINCT n.t√™n_nguy√™n_li·ªáu) AS nguyen_lieu,
                collect(DISTINCT e.t√™n_c√¥ng_hi·ªáu) AS cong_hieu
            LIMIT $limit
            """
            results = session.run(query, query_text=query_text, limit=limit)
            return self._format_results(results, "tri·ªáu ch·ª©ng")
        return execute
    
    def _query_by_ingredient(self, query_text: str, limit: int):
        """Query 3: T√¨m theo NGUY√äN_LI·ªÜU - FIXED"""
        def execute(session):
            query = """
            MATCH (r:B√ÄI_THU·ªêC)-[rel:CH·ª®A_NGUY√äN_LI·ªÜU]->(n:NGUY√äN_LI·ªÜU)
            WHERE toLower(n.t√™n_nguy√™n_li·ªáu) CONTAINS toLower($query_text)
            OPTIONAL MATCH (r)-[:ƒêI·ªÄU_TR·ªä]->(b:B·ªÜNH)
            OPTIONAL MATCH (r)-[:C√ì_C√îNG_HI·ªÜU]->(e:C√îNG_HI·ªÜU)
            OPTIONAL MATCH (n)-[:L√Ä_D∆Ø·ª¢C_LI·ªÜU_T·ª™]->(c:C√ÇY_THU·ªêC)
            RETURN DISTINCT
                r.t√™n_b√†i_thu·ªëc AS ten_bai_thuoc,
                n.t√™n_nguy√™n_li·ªáu AS nguyen_lieu_chinh,
                r.li·ªÅu_l∆∞·ª£ng_c√°ch_d√πng AS lieu_luong,  // ‚Üê S·ª¨A: L·∫•y t·ª´ node B√ÄI_THU·ªêC
                c.t√™n_ch√≠nh AS cay_thuoc,
                c.t√≠nh_v·ªã_t√°c_d·ª•ng AS tinh_vi,
                collect(DISTINCT b.t√™n_b·ªánh) AS benh,
                collect(DISTINCT e.t√™n_c√¥ng_hi·ªáu) AS cong_hieu
            LIMIT $limit
            """
            results = session.run(query, query_text=query_text, limit=limit)
            return self._format_results(results, "nguy√™n li·ªáu")
        return execute
    
    def _query_by_effect(self, query_text: str, limit: int):
        """Query 4: T√¨m theo C√îNG_HI·ªÜU"""
        def execute(session):
            query = """
            MATCH (r:B√ÄI_THU·ªêC)-[:C√ì_C√îNG_HI·ªÜU]->(e:C√îNG_HI·ªÜU)
            WHERE toLower(e.t√™n_c√¥ng_hi·ªáu) CONTAINS toLower($query_text)
            OPTIONAL MATCH (r)-[:ƒêI·ªÄU_TR·ªä]->(b:B·ªÜNH)
            OPTIONAL MATCH (r)-[rel:CH·ª®A_NGUY√äN_LI·ªÜU]->(n:NGUY√äN_LI·ªÜU)
            RETURN DISTINCT
                r.t√™n_b√†i_thu·ªëc AS ten_bai_thuoc,
                e.t√™n_c√¥ng_hi·ªáu AS cong_hieu_chinh,
                r.li·ªÅu_l∆∞·ª£ng_c√°ch_d√πng AS lieu_luong,
                collect(DISTINCT b.t√™n_b·ªánh) AS benh,
                collect(DISTINCT n.t√™n_nguy√™n_li·ªáu) AS nguyen_lieu
            LIMIT $limit
            """
            results = session.run(query, query_text=query_text, limit=limit)
            return self._format_results(results, "c√¥ng hi·ªáu")
        return execute
    
    def _query_by_remedy_name(self, query_text: str, limit: int):
        """Query 5: T√¨m theo t√™n B√ÄI_THU·ªêC"""
        def execute(session):
            query = """
            MATCH (r:B√ÄI_THU·ªêC)
            WHERE toLower(r.t√™n_b√†i_thu·ªëc) CONTAINS toLower($query_text)
            OPTIONAL MATCH (r)-[:ƒêI·ªÄU_TR·ªä]->(b:B·ªÜNH)
            OPTIONAL MATCH (r)-[rel:CH·ª®A_NGUY√äN_LI·ªÜU]->(n:NGUY√äN_LI·ªÜU)
            OPTIONAL MATCH (r)-[:C√ì_C√îNG_HI·ªÜU]->(e:C√îNG_HI·ªÜU)
            RETURN DISTINCT
                r.t√™n_b√†i_thu·ªëc AS ten_bai_thuoc,
                r.li·ªÅu_l∆∞·ª£ng_c√°ch_d√πng AS lieu_luong,
                r.ch√∫_√Ω AS chu_y,
                collect(DISTINCT b.t√™n_b·ªánh) AS benh,
                collect(DISTINCT n.t√™n_nguy√™n_li·ªáu) AS nguyen_lieu,
                collect(DISTINCT e.t√™n_c√¥ng_hi·ªáu) AS cong_hieu
            LIMIT $limit
            """
            results = session.run(query, query_text=query_text, limit=limit)
            return self._format_results(results, "t√™n b√†i thu·ªëc")
        return execute
    
    def _query_by_herb(self, query_text: str, limit: int):
        """Query 6: T√¨m theo C√ÇY_THU·ªêC - IMPROVED"""
        def execute(session):
            # T·∫°o variants ƒë·ªÉ t√¨m ki·∫øm
            search_variants = TextNormalizer.create_search_variants(query_text)
            
            # T√¨m v·ªõi nhi·ªÅu ƒëi·ªÅu ki·ªán
            query = """
            MATCH (c:C√ÇY_THU·ªêC)
            WHERE toLower(c.t√™n_ch√≠nh) CONTAINS toLower($query_text)
               OR toLower(c.t√™n_khoa_h·ªçc) CONTAINS toLower($query_text)
               OR toLower(c.h·ªç) CONTAINS toLower($query_text)
               OR ANY(variant IN $variants WHERE toLower(c.t√™n_ch√≠nh) CONTAINS toLower(variant))
               OR toLower(c.t√™n_kh√°c) CONTAINS toLower($query_text)
            
            OPTIONAL MATCH (c)<-[:L√Ä_D∆Ø·ª¢C_LI·ªÜU_T·ª™]-(n:NGUY√äN_LI·ªÜU)<-[:CH·ª®A_NGUY√äN_LI·ªÜU]-(r:B√ÄI_THU·ªêC)
            OPTIONAL MATCH (c)-[:C√ì_T√äN_G·ªåI_KH√ÅC]->(tk:T√äN_KH√ÅC)
            OPTIONAL MATCH (c)-[:THU·ªòC_H·ªå]->(h:H·ªå_TH·ª∞C_V·∫¨T)
            OPTIONAL MATCH (c)-[:S·ª¨_D·ª§NG_B·ªò_PH·∫¨N]->(bp:B·ªò_PH·∫¨N_D√ôNG)
            OPTIONAL MATCH (c)-[:CH·ª®A_TH√ÄNH_PH·∫¶N]->(tp:TH√ÄNH_PH·∫¶N_H√ìA_H·ªåC)
            
            RETURN DISTINCT
                c.t√™n_ch√≠nh AS ten_cay_thuoc,
                c.t√™n_khoa_h·ªçc AS ten_khoa_hoc,
                c.t√™n_kh√°c AS ten_khac_str,
                c.h·ªç AS ho,
                c.m√¥_t·∫£ AS mo_ta,
                c.n∆°i_s·ªëng_thu_h√°i AS noi_song,
                c.th√†nh_ph·∫ßn_h√≥a_h·ªçc AS thanh_phan_hoa_hoc,
                c.t√≠nh_v·ªã_t√°c_d·ª•ng AS tinh_vi,
                c.c√¥ng_d·ª•ng_ch·ªâ_ƒë·ªãnh AS cong_dung,
                c.li·ªÅu_d√πng AS lieu_dung,
                c.ƒë∆°n_thu·ªëc AS don_thuoc,
                collect(DISTINCT tk.t√™n) AS ten_khac,
                collect(DISTINCT h.t√™n_h·ªç) AS ho_thuc_vat,
                collect(DISTINCT bp.t√™n_b·ªô_ph·∫≠n) AS cac_bo_phan,
                collect(DISTINCT tp.t√™n) AS cac_thanh_phan,
                collect(DISTINCT r.t√™n_b√†i_thu·ªëc)[..5] AS bai_thuoc_su_dung
            LIMIT $limit
            """
            results = session.run(query, 
                                query_text=query_text, 
                                variants=search_variants,
                                limit=limit)
            return self._format_herb_results(results, "c√¢y thu·ªëc")
        return execute
    
    def _format_results(self, results, query_type: str) -> List[Dict]:
        """Format k·∫øt qu·∫£ t·ª´ Neo4j - FIXED"""
        entities = []
        for record in results:
            ten_bai = record.get('ten_bai_thuoc', 'N/A')
            
            if not ten_bai or str(ten_bai) == 'None':
                continue
            
            description_parts = []
            
            # B·ªánh
            if 'ten_benh' in record and record['ten_benh']:
                description_parts.append(f"**Ch·ªØa b·ªánh:** {record['ten_benh']}")
            elif 'benh' in record:
                benh_list = [b for b in record.get('benh', []) if b and str(b) != 'None']
                if benh_list:
                    description_parts.append(f"**Ch·ªØa b·ªánh:** {', '.join(benh_list)}")
            
            # Tri·ªáu ch·ª©ng
            if 'trieu_chung_chinh' in record and record['trieu_chung_chinh']:
                description_parts.append(f"**Tri·ªáu ch·ª©ng:** {record['trieu_chung_chinh']}")
            elif 'trieu_chung' in record:
                tc_list = [tc for tc in record.get('trieu_chung', []) if tc and str(tc) != 'None']
                if tc_list:
                    description_parts.append(f"**Tri·ªáu ch·ª©ng:** {', '.join(tc_list)}")
            
            # Nguy√™n li·ªáu
            if 'nguyen_lieu_chinh' in record and record['nguyen_lieu_chinh']:
                description_parts.append(f"**Nguy√™n li·ªáu ch√≠nh:** {record['nguyen_lieu_chinh']}")
                
                # Th√¥ng tin c√¢y thu·ªëc
                if record.get('cay_thuoc'):
                    description_parts.append(f"  - Ngu·ªìn g·ªëc: {record['cay_thuoc']}")
                if record.get('tinh_vi'):
                    description_parts.append(f"  - T√≠nh v·ªã: {record['tinh_vi'][:200]}...")
            
            nguyen_lieu = [nl for nl in record.get('nguyen_lieu', []) if nl and str(nl) != 'None']
            if nguyen_lieu:
                description_parts.append(f"**Th√†nh ph·∫ßn:** {', '.join(nguyen_lieu[:10])}")
            
            # C√¥ng hi·ªáu
            if 'cong_hieu_chinh' in record and record['cong_hieu_chinh']:
                description_parts.append(f"**C√¥ng hi·ªáu ch√≠nh:** {record['cong_hieu_chinh']}")
            
            cong_hieu = [ch for ch in record.get('cong_hieu', []) if ch and str(ch) != 'None']
            if cong_hieu:
                description_parts.append(f"**C√°c c√¥ng hi·ªáu:** {', '.join(cong_hieu)}")
            
            # Li·ªÅu l∆∞·ª£ng - S·ª¨A ƒê√ÇY
            lieu_luong = record.get('lieu_luong', '')
            if lieu_luong and str(lieu_luong) != 'None':
                # R√∫t ng·∫Øn n·∫øu qu√° d√†i
                if len(str(lieu_luong)) > 500:
                    description_parts.append(f"**Li·ªÅu l∆∞·ª£ng & C√°ch d√πng:** {str(lieu_luong)[:500]}...")
                else:
                    description_parts.append(f"**Li·ªÅu l∆∞·ª£ng & C√°ch d√πng:** {lieu_luong}")
            
            # Ch√∫ √Ω
            chu_y = record.get('chu_y', '')
            if chu_y and str(chu_y) != 'None':
                description_parts.append(f"**Ch√∫ √Ω:** {str(chu_y)[:300]}...")
            
            # ƒê·ªëi t∆∞·ª£ng
            doi_tuong = record.get('doi_tuong', '')
            if doi_tuong and str(doi_tuong) != 'None':
                description_parts.append(f"**ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p:** {doi_tuong}")
            
            if description_parts:
                entities.append({
                    'ten_bai_thuoc': ten_bai,
                    'description': '\n'.join(description_parts),
                    'query_type': query_type
                })
        
        if entities:
            print(f"   ‚úì T√¨m th·∫•y {len(entities)} b√†i thu·ªëc (theo {query_type})")
        
        return entities

    def _format_herb_results(self, results, query_type: str) -> List[Dict]:
        """Format k·∫øt qu·∫£ t·ª´ Neo4j cho C√ÇY_THU·ªêC"""
        entities = []
        for record in results:
            ten_cay = record.get('ten_cay_thuoc', 'N/A')
            
            if not ten_cay or str(ten_cay) == 'None':
                continue
            
            description_parts = []
            
            # T√™n khoa h·ªçc
            if record.get('ten_khoa_hoc'):
                description_parts.append(f"**T√™n khoa h·ªçc:** _{record['ten_khoa_hoc']}_")
            
            # H·ªç th·ª±c v·∫≠t
            if record.get('ho'):
                description_parts.append(f"**H·ªç:** {record['ho']}")
            
            # T√™n kh√°c
            ten_khac = [tk for tk in record.get('ten_khac', []) if tk and str(tk) != 'None']
            if ten_khac:
                description_parts.append(f"**T√™n g·ªçi kh√°c:** {', '.join(ten_khac)}")
            
            # M√¥ t·∫£
            mo_ta = record.get('mo_ta', '')
            if mo_ta and str(mo_ta) != 'None':
                description_parts.append(f"**M√¥ t·∫£:** {str(mo_ta)[:300]}...")
            
            # B·ªô ph·∫≠n d√πng
            if record.get('bo_phan_dung'):
                description_parts.append(f"**B·ªô ph·∫≠n d√πng:** {record['bo_phan_dung']}")
            
            # N∆°i s·ªëng
            if record.get('noi_song'):
                description_parts.append(f"**N∆°i s·ªëng v√† thu h√°i:** {str(record['noi_song'])[:200]}...")
            
            # Th√†nh ph·∫ßn h√≥a h·ªçc
            if record.get('thanh_phan_hoa_hoc'):
                description_parts.append(f"**Th√†nh ph·∫ßn h√≥a h·ªçc:** {str(record['thanh_phan_hoa_hoc'])[:200]}...")
            
            # T√≠nh v·ªã t√°c d·ª•ng
            tinh_vi = record.get('tinh_vi', '')
            if tinh_vi and str(tinh_vi) != 'None':
                description_parts.append(f"**T√≠nh v·ªã, t√°c d·ª•ng:** {str(tinh_vi)[:300]}...")
            
            # Li·ªÅu d√πng
            if record.get('lieu_dung'):
                description_parts.append(f"**Li·ªÅu d√πng:** {record['lieu_dung']}")
            
            # B√†i thu·ªëc s·ª≠ d·ª•ng
            bai_thuoc = [bt for bt in record.get('bai_thuoc_su_dung', []) if bt and str(bt) != 'None']
            if bai_thuoc:
                description_parts.append(f"**C√°c b√†i thu·ªëc s·ª≠ d·ª•ng:** {', '.join(bai_thuoc)}")
            
            if description_parts:
                entities.append({
                    'ten_bai_thuoc': ten_cay,  # Gi·ªØ key n√†y ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi OllamaService
                    'description': '\n'.join(description_parts),
                    'query_type': query_type
                })
        
        if entities:
            print(f"   ‚úì T√¨m th·∫•y {len(entities)} c√¢y thu·ªëc")
        
        return entities

    def query_dongyi_kg(self, query_text: str, limit: int = 5) -> List[Dict]:
        """Truy v·∫•n Knowledge Graph V2 - Ph√°t hi·ªán th√¥ng minh"""
        try:
            with self.driver.session(database=self.database) as session:
                # Debug
                count_result = session.run("MATCH (n) RETURN count(n) as total")
                total_entities = count_result.single()["total"]
                print(f"   üìä Database c√≥ {total_entities} nodes")
                
                if total_entities == 0:
                    print(f"   ‚ö†Ô∏è  Database '{self.database}' tr·ªëng!")
                    return []
                
                # Ph√°t hi·ªán lo·∫°i query
                query_type = self.preprocessor.detect_query_type(query_text)
                print(f"   üéØ Lo·∫°i c√¢u h·ªèi: {query_type.upper()}")
                
                # Tr√≠ch xu·∫•t keywords
                search_patterns = self.preprocessor.build_search_patterns(query_text)
                print(f"   üîç T√¨m ki·∫øm v·ªõi keywords: {search_patterns[:3]}")
                
                for pattern in search_patterns:
                    print(f"      ‚Üí Th·ª≠ pattern: '{pattern}'")
                    
                    # Ch·ªçn th·ª© t·ª± query d·ª±a tr√™n lo·∫°i c√¢u h·ªèi
                    if query_type == "herb":
                        queries = [
                            self._query_by_herb(pattern, limit),
                            self._query_by_ingredient(pattern, limit),
                            self._query_by_remedy_name(pattern, limit)
                        ]
                    else:
                        queries = [
                            self._query_by_disease(pattern, limit),
                            self._query_by_symptom(pattern, limit),
                            self._query_by_ingredient(pattern, limit),
                            self._query_by_effect(pattern, limit),
                            self._query_by_remedy_name(pattern, limit),
                            self._query_by_herb(pattern, limit)
                        ]
                
                    for query_func in queries:
                        try:
                            results = query_func(session)
                            if results:
                                return results
                        except Exception as e:
                            continue
            
            print("   ‚úó Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ v·ªõi t·∫•t c·∫£ patterns")
            return []
                
        except Exception as e:
            print(f"‚ùå L·ªói truy v·∫•n Neo4j: {e}")
            traceback.print_exc()
            return []

# --- RAG System ---
async def interactive_rag_query():
    """H·ªá th·ªëng RAG t∆∞∆°ng t√°c - Neo4j + Ollama"""
    print("\n" + "="*70)
    print("üè• H·ªÜ TH·ªêNG RAG TRA C·ª®U ƒê√îNG Y V2 (OLLAMA)")
    print("="*70)
    print("Nh·∫≠p 'exit' ƒë·ªÉ tho√°t, 'help' ƒë·ªÉ xem h∆∞·ªõng d·∫´n")
    print("Nh·∫≠p 'mode' ƒë·ªÉ chuy·ªÉn ch·∫ø ƒë·ªô (rag/raw)")
    print("="*70 + "\n")
    
    try:
        neo4j_helper = DongyiQueryHelper(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD, NEO4J_DATABASE)
        with neo4j_helper.driver.session(database=neo4j_helper.database) as session:
            session.run("RETURN 1")
        print("‚úì K·∫øt n·ªëi Neo4j th√†nh c√¥ng")
    except Exception as e:
        print(f"‚úó Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Neo4j: {e}")
        return
    
    ollama_service = None
    try:
        ollama_service = OllamaService()
        print("‚úì K·∫øt n·ªëi Ollama th√†nh c√¥ng\n")
    except Exception as e:
        print(f"‚ö†Ô∏è  Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Ollama: {e}")
        print("   S·∫Ω ch·∫°y ·ªü ch·∫ø ƒë·ªô 'raw' (ch·ªâ hi·ªÉn th·ªã d·ªØ li·ªáu th√¥)\n")
    
    mode = "rag" if ollama_service else "raw"
    
    try:
        while True:
            try:
                print("‚îÄ" * 70)
                print(f"[Ch·∫ø ƒë·ªô: {mode.upper()}] [Model: {OLLAMA_MODEL}]")
                user_query = input("üí¨ C√¢u h·ªèi: ").strip()
                
                if user_query.lower() == 'exit':
                    print("\nüëã T·∫°m bi·ªát!")
                    break
                elif user_query.lower() == 'help':
                    print_help()
                    continue
                elif user_query.lower() == 'mode':
                    if ollama_service:
                        mode = "raw" if mode == "rag" else "rag"
                        print(f"‚úì ƒê√£ chuy·ªÉn sang ch·∫ø ƒë·ªô: {mode.upper()}")
                    else:
                        print("‚ö†Ô∏è  Ollama ch∆∞a k·∫øt n·ªëi, kh√¥ng th·ªÉ d√πng ch·∫ø ƒë·ªô RAG")
                    continue
                elif not user_query:
                    print("‚ö†Ô∏è  Vui l√≤ng nh·∫≠p c√¢u h·ªèi!")
                    continue
                
                print(f"\nüîç ƒêang t√¨m ki·∫øm...\n")
                
                context = neo4j_helper.query_dongyi_kg(user_query, limit=5)
                
                if not context:
                    print("‚ùå Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan")
                    print("üí° Th·ª≠ t·ª´ kh√≥a: 's·ªët', 'ho', 'ƒëau ƒë·∫ßu', 'l√° tre', 'th·∫°ch cao', 'thanh nhi·ªát'\n")
                    continue
                
                if mode == "rag" and ollama_service:
                    print("=" * 70)
                    answer = ollama_service.generate_answer(user_query, context)
                    print(answer)
                    print("=" * 70)
                else:
                    print(f"üìã K·∫æT QU·∫¢ T√åM KI·∫æM ({len(context)} b√†i thu·ªëc):\n")
                    for i, entity in enumerate(context, 1):
                        print(f"{'‚îÄ'*70}")
                        print(f"üîπ B√ÄI THU·ªêC {i}: {entity['ten_bai_thuoc']}")
                        print(f"{'‚îÄ'*70}")
                        print(entity['description'])
                        print()
                
            except KeyboardInterrupt:
                print("\n\nüëã T·∫°m bi·ªát!")
                break
            except Exception as e:
                print(f"‚ùå L·ªói: {e}")
                traceback.print_exc()
        
    finally:
        neo4j_helper.close()
        print("\n‚úì ƒê√£ ƒë√≥ng k·∫øt n·ªëi Neo4j")


def print_help():
    print("\n" + "="*70)
    print("üìñ H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG")
    print("="*70)
    print("‚Ä¢ Nh·∫≠p c√¢u h·ªèi v·ªÅ ƒê√¥ng y ƒë·ªÉ t√¨m ki·∫øm b√†i thu·ªëc")
    print("‚Ä¢ 'help' - Xem h∆∞·ªõng d·∫´n")
    print("‚Ä¢ 'mode' - Chuy·ªÉn ƒë·ªïi gi·ªØa ch·∫ø ƒë·ªô RAG v√† RAW")
    print("‚Ä¢ 'exit' - Tho√°t ch∆∞∆°ng tr√¨nh")
    print("\nüí° V√ç D·ª§ C√ÇU H·ªéI:")
    print("   - B√†i thu·ªëc ch·ªØa s·ªët cao")
    print("   - Thu·ªëc n√†o c√≥ l√° tre")
    print("   - C√¥ng hi·ªáu thanh nhi·ªát")
    print("   - Ch·ªØa ho kh√°t n∆∞·ªõc")
    print("   - Tri·ªáu ch·ª©ng s·ªët bu·ªìn phi·ªÅn")
    print("="*70 + "\n")


async def main():
    try:
        await interactive_rag_query()
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    try:
        logging.basicConfig(level=logging.ERROR)
        asyncio.run(main())
        print("\n‚úì Ch∆∞∆°ng tr√¨nh ho√†n t·∫•t!\n")
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  D·ª´ng b·ªüi ng∆∞·ªùi d√πng\n")